* preprocessing

python preprocess.py --source-lang gold --target-lang mb --trainpref ~/NMT_experiments/MBOSHI/files/train --validpref ~/NMT_experiments/MBOSHI/files/dev --testpref ~/NMT_experiments/MBOSHI/files/corpus --destdir data-bin/mboshi2grapheme

python preprocess.py --source-lang fr --target-lang ph --trainpref ~/Interspeech_models/temp10_same/true_phones/files/train --validpref ~/Interspeech_models/temp10_same/true_phones/files/dev --testpref ~/Interspeech_models/temp10_same/true_phones/files/corpus --destdir data-bin/french2truephones

python preprocess.py --source-lang fr --target-lang ph --trainpref ~/Interspeech_models/temp10_same/mfcc_hmm/files/train --validpref ~/Interspeech_models/temp10_same/mfcc_hmm/files/dev --testpref ~/Interspeech_models/temp10_same/mfcc_hmm/files/corpus --destdir data-bin/french2mfcchmm

* training
CUDA_VISIBLE_DEVICES=0 nohup python train.py data-bin/mboshi2grapheme --arch transformer -s gold -t mb \
--dropout 0.5 --encoder-embed-dim 64 --encoder-ffn-embed-dim 64 --encoder-layers 3 --encoder-attention-heads 1 \
--decoder-embed-dim 64 --decoder-ffn-embed-dim 64 --decoder-layers 3 --decoder-attention-heads 1 \
--optimizer adam --lr 0.0005 --label-smoothing 0.1 --max-tokens 2000 --min-lr '1e-09' \
--lr-scheduler inverse_sqrt --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --max-update 50000 \
--warmup-updates 4000 --warmup-init-lr '1e-07' --adam-betas '(0.9, 0.98)' --save-dir ../MB_transformer_attention/mboshi2grapheme/1head_3layers/ > ../MB_transformer_attention/mboshi2grapheme/1head_3layers/traning_log 2>&1  &


CUDA_VISIBLE_DEVICES=0 nohup python train.py data-bin/french2truephones --arch transformer -s fr -t ph \
--dropout 0.5 --encoder-embed-dim 64 --encoder-ffn-embed-dim 64 --encoder-layers 3 --encoder-attention-heads 4 \
--decoder-embed-dim 64 --decoder-ffn-embed-dim 64 --decoder-layers 3 --decoder-attention-heads 4 \
--optimizer adam --lr 0.0005 --label-smoothing 0.1 --max-tokens 4000 --min-lr '1e-09' \
--lr-scheduler inverse_sqrt --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --max-update 50000 \
--warmup-updates 4000 --warmup-init-lr '1e-07' --adam-betas '(0.9, 0.98)' --save-dir checkpoints/french2truephones > french_log 2>&1  &


python retrieve_alignment.py data-bin/iwslt14.tokenized.de-en --path checkpoints/transformer/checkpoint_best.pt --cpu --beam 1 --print-alignment --batch-size 1

